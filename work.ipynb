{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 预处理：提取出单个站点内的所有因子"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "ids_shangban = [ '天宝大水港排涝站','中排渠涝站（天宝）',\n",
    "              '甘棠溪慧民花园监测点',\n",
    "        '康山溪金峰花园监测点', '芗城水利局站','中山桥水闸站', '北京路水闸站','九湖监测点','桂林排涝站','上坂']\n",
    "\n",
    "\n",
    "input_file,root_dir,\\\n",
    "include_site,include_factor,\\\n",
    "seq_length_x,seq_length_y = './data/water/shangban/water_4H.csv',\\\n",
    "  './data/water/shangban/singSiteMulFac',[0,1,2,3,6,8],\\\n",
    "    ids_shangban,24,3\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = [i + 3 for i in include_factor]\n",
    "cols = [1, 2] + cols\n",
    "\n",
    "df = pd.read_csv(input_file, usecols=cols)\n",
    "merge = None\n",
    "for site in include_site:\n",
    "    one = df.loc[df['站点名称'] == site]\n",
    "    one.columns = ['time', 'site'] + [site + factors[i] for i in include_factor]\n",
    "    one.drop(columns=['site'], axis=1, inplace=True)\n",
    "    merge = one if merge is None else pd.merge(merge, one, on='time')\n",
    "\n",
    "merge.set_index(keys='time', inplace=True)\n",
    "\n",
    "exi = os.path.exists(root_dir)\n",
    "if not exi:\n",
    "    os.mkdir(root_dir)\n",
    "# 保存\n",
    "merge.to_csv(root_dir+'/data.csv', encoding='utf_8_sig')\n",
    "\n",
    "x_offsets = np.sort(np.concatenate((np.arange(-(seq_length_x - 1), 1, 1),)))\n",
    "y_offsets = np.sort(np.arange(1, (seq_length_y + 1), 1))\n",
    "x, y = generate_graph_seq2seq_io_data(\n",
    "    merge,\n",
    "    x_offsets=x_offsets,\n",
    "    y_offsets=y_offsets,\n",
    "    add_time_in_day=True,\n",
    ")\n",
    "print(\"x shape: \", x.shape, \", y shape: \", y.shape)\n",
    "# 随机打乱！\n",
    "per = np.random.permutation(x.shape[0])\n",
    "x = x[per]\n",
    "y = y[per]\n",
    "\n",
    "# Write the data into npz file.\n",
    "num_samples = x.shape[0]\n",
    "num_test = round(num_samples * 0.2)\n",
    "num_train = round(num_samples * 0.7)\n",
    "num_val = num_samples - num_test - num_train\n",
    "x_train, y_train = x[:num_train], y[:num_train]\n",
    "x_val, y_val = (\n",
    "    x[num_train: num_train + num_val],\n",
    "    y[num_train: num_train + num_val],\n",
    ")\n",
    "x_test, y_test = x[-num_test:], y[-num_test:]\n",
    "\n",
    "for cat in [\"train\", \"val\", \"test\"]:\n",
    "    _x, _y = locals()[\"x_\" + cat], locals()[\"y_\" + cat]\n",
    "    print(cat, \"x: \", _x.shape, \"y:\", _y.shape)\n",
    "    np.savez_compressed(\n",
    "        os.path.join(root_dir+'/', f\"{cat}.npz\"),\n",
    "        x=_x,\n",
    "        y=_y,\n",
    "        x_offsets=x_offsets.reshape(list(x_offsets.shape) + [1]),\n",
    "        y_offsets=y_offsets.reshape(list(y_offsets.shape) + [1]),\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14., grad_fn=<SumBackward0>)\n",
      "tensor([2., 4., 6.])\n",
      "tensor([[0., 2., 0., 0.],\n",
      "        [0., 0., 4., 0.],\n",
      "        [0., 0., 0., 6.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([1.0,2,3],requires_grad=True)\n",
    "x_matrix = torch.zeros([4,4])\n",
    "for i in range(3):\n",
    "    x_matrix[i][i+1] = x[i]\n",
    "adj = torch.zeros([4,4],requires_grad=True)\n",
    "adj1 = adj + x_matrix\n",
    "adj2 = adj1 * adj1\n",
    "adj2 = adj2.sum()\n",
    "\n",
    "# print(type(adj))\n",
    "print(adj2)\n",
    "adj2.backward()\n",
    "# out = adj\n",
    "\n",
    "\n",
    "print(x.grad)\n",
    "print(adj.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "x_ma = torch.zeros([2,4,4])\n",
    "print(x_ma)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% test\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}