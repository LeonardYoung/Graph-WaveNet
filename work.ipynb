{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "爬取漳州历史天气数据\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import requests\n",
    "header = {\n",
    "    'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36',\n",
    "}\n",
    "res_list = []\n",
    "for year in range(2020,2022):\n",
    "    for month in range(1,13):\n",
    "        url = 'https://lishi.tianqi.com/zhangzhou/{}{:0>2d}.html'.format(year,month)\n",
    "        # print(url)\n",
    "        res = requests.get(url=url,headers=header)\n",
    "        res_list.append(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "# 2020年每天的天气情况\n",
    "day = 1\n",
    "csv_str = \"\"\n",
    "for month in range(1,13):\n",
    "    dom = etree.HTML(res_list[month].text)\n",
    "    values = dom.xpath('/html/body/div[7]/div[1]/div[4]/ul/li')\n",
    "    for one in values:\n",
    "        high_temp = int(one.xpath('./div[2]/text()')[0][0:-1])\n",
    "        low_temp = int(one.xpath('./div[3]/text()')[0][0:-1])\n",
    "        weather = one.xpath('./div[4]/text()')[0]\n",
    "\n",
    "        # print(day,high_temp,low_temp,weather)\n",
    "        line = \"{},{},{},{}\\n\".format(day,high_temp,low_temp,weather)\n",
    "        csv_str = csv_str + line\n",
    "        day += 1\n",
    "\n",
    "head_str = \"day,high,low,weather\\n\"\n",
    "csv_str = head_str + csv_str\n",
    "# print(csv_str)\n",
    "with open('weather.csv','w',encoding='utf-8') as f:\n",
    "    f.write(csv_str)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "         天宝大水港排涝站0   中排渠涝站（天宝）0  程溪下庄工业区水质监测点0  甘棠溪慧民花园监测点0  康山溪金峰花园监测点0  \\\ncount  8784.000000  8784.000000    8784.000000  8784.000000  8784.000000   \nmean      6.558555     6.322410       6.646223     6.399332     7.104915   \nstd       1.160994     0.922257       0.353787     1.214922     0.902649   \nmin       0.940000     0.000000       4.350000     0.000000     3.820000   \n25%       5.750000     5.700000       6.470000     6.120000     6.520000   \n50%       6.530000     6.410000       6.570000     6.610000     6.920000   \n75%       7.320000     6.980000       6.950000     7.000000     7.580000   \nmax       9.560000     9.830000       7.940000    12.520000    12.670000   \n\n           芗城水利局站0      中山桥水闸站0      北京路水闸站0       九湖监测点0       桂林排涝站0  \\\ncount  8784.000000  8784.000000  8784.000000  8784.000000  8784.000000   \nmean      6.218743     5.914457     6.844680     6.183382     7.011030   \nstd       1.697479     1.133257     1.302965     1.933982     0.921748   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       5.020000     5.540000     6.040000     5.290000     6.690000   \n50%       6.238500     6.050000     6.780000     6.110000     6.940000   \n75%       7.530000     6.620000     7.430000     7.222500     7.330000   \nmax      10.130000     9.560000    14.000000    13.800000    11.470000   \n\n               上坂0  \ncount  8784.000000  \nmean      6.939061  \nstd       0.503949  \nmin       4.376000  \n25%       6.548000  \n50%       6.998000  \n75%       7.238000  \nmax       9.792000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>天宝大水港排涝站0</th>\n      <th>中排渠涝站（天宝）0</th>\n      <th>程溪下庄工业区水质监测点0</th>\n      <th>甘棠溪慧民花园监测点0</th>\n      <th>康山溪金峰花园监测点0</th>\n      <th>芗城水利局站0</th>\n      <th>中山桥水闸站0</th>\n      <th>北京路水闸站0</th>\n      <th>九湖监测点0</th>\n      <th>桂林排涝站0</th>\n      <th>上坂0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>6.558555</td>\n      <td>6.322410</td>\n      <td>6.646223</td>\n      <td>6.399332</td>\n      <td>7.104915</td>\n      <td>6.218743</td>\n      <td>5.914457</td>\n      <td>6.844680</td>\n      <td>6.183382</td>\n      <td>7.011030</td>\n      <td>6.939061</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.160994</td>\n      <td>0.922257</td>\n      <td>0.353787</td>\n      <td>1.214922</td>\n      <td>0.902649</td>\n      <td>1.697479</td>\n      <td>1.133257</td>\n      <td>1.302965</td>\n      <td>1.933982</td>\n      <td>0.921748</td>\n      <td>0.503949</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.940000</td>\n      <td>0.000000</td>\n      <td>4.350000</td>\n      <td>0.000000</td>\n      <td>3.820000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.376000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.750000</td>\n      <td>5.700000</td>\n      <td>6.470000</td>\n      <td>6.120000</td>\n      <td>6.520000</td>\n      <td>5.020000</td>\n      <td>5.540000</td>\n      <td>6.040000</td>\n      <td>5.290000</td>\n      <td>6.690000</td>\n      <td>6.548000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>6.530000</td>\n      <td>6.410000</td>\n      <td>6.570000</td>\n      <td>6.610000</td>\n      <td>6.920000</td>\n      <td>6.238500</td>\n      <td>6.050000</td>\n      <td>6.780000</td>\n      <td>6.110000</td>\n      <td>6.940000</td>\n      <td>6.998000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.320000</td>\n      <td>6.980000</td>\n      <td>6.950000</td>\n      <td>7.000000</td>\n      <td>7.580000</td>\n      <td>7.530000</td>\n      <td>6.620000</td>\n      <td>7.430000</td>\n      <td>7.222500</td>\n      <td>7.330000</td>\n      <td>7.238000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.560000</td>\n      <td>9.830000</td>\n      <td>7.940000</td>\n      <td>12.520000</td>\n      <td>12.670000</td>\n      <td>10.130000</td>\n      <td>9.560000</td>\n      <td>14.000000</td>\n      <td>13.800000</td>\n      <td>11.470000</td>\n      <td>9.792000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "#\n",
    "# # 按照上下游顺序\n",
    "# ids = [ '天宝大水港排涝站','中排渠涝站（天宝）',\n",
    "#              '程溪下庄工业区水质监测点', '甘棠溪慧民花园监测点',\n",
    "#         '康山溪金峰花园监测点', '芗城水利局站','中山桥水闸站', '北京路水闸站','九湖监测点','桂林排涝站','上坂']\n",
    "# df = pd.read_csv('data/water/water2020.csv', usecols=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "# merge = None\n",
    "# for site in ids:\n",
    "#     one = df.loc[df['站点名称'] == site]\n",
    "#     one.columns = ['time', 'site'] + [site + str(i) for i in range(9)]\n",
    "#     one = one[['time'] + [site + str(inc)]]\n",
    "#     if merge is None:\n",
    "#         merge = one\n",
    "#     else:\n",
    "#         merge = pd.merge(merge, one, on='time')\n",
    "# merge.set_index(keys='time', inplace=True)\n",
    "\n",
    "# df = pd.read_hdf(file_name)\n",
    "# df.describe()\n",
    "# merge.to_hdf(file_name, key='merge', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     天宝大水港排涝站0  中排渠涝站（天宝）0  程溪下庄工业区水质监测点0  甘棠溪慧民花园监测点0  \\\n",
      "time                                                                     \n",
      "2020-01-01 00:00:00       8.25        6.32           6.95         7.11   \n",
      "2020-01-01 01:00:00       8.37        6.23           6.95         7.04   \n",
      "2020-01-01 02:00:00       8.23        6.30           6.95         7.11   \n",
      "2020-01-01 03:00:00       8.17        6.29           6.95         7.11   \n",
      "2020-01-01 04:00:00       8.10        6.32           6.95         7.08   \n",
      "\n",
      "                     康山溪金峰花园监测点0  芗城水利局站0  中山桥水闸站0  北京路水闸站0  九湖监测点0  桂林排涝站0  \\\n",
      "time                                                                          \n",
      "2020-01-01 00:00:00         6.41     8.16     1.75     6.27    6.98    8.29   \n",
      "2020-01-01 01:00:00         6.46     8.17     2.63     6.26    6.72    8.30   \n",
      "2020-01-01 02:00:00         6.46     8.11     2.64     6.22    6.73    8.28   \n",
      "2020-01-01 03:00:00         6.48     8.22     2.67     6.21    6.73    8.28   \n",
      "2020-01-01 04:00:00         6.45     8.21     1.75     6.27    6.98    8.40   \n",
      "\n",
      "                       上坂0  \n",
      "time                        \n",
      "2020-01-01 00:00:00  6.842  \n",
      "2020-01-01 01:00:00  6.834  \n",
      "2020-01-01 02:00:00  6.888  \n",
      "2020-01-01 03:00:00  6.871  \n",
      "2020-01-01 04:00:00  6.856  \n"
     ]
    }
   ],
   "source": [
    "# print(df.head(5))\n",
    "# import util\n",
    "# # col_line =  df.iloc[0]\n",
    "# col_line = df.iloc[:,0]\n",
    "#\n",
    "# util.DataLoader()\n",
    "\n",
    "\n",
    "# print(col_li)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (8758, 24) , y shape:  (8758, 3)\n",
      "train x:  (6131, 24) y: (6131, 3)\n",
      "val x:  (875, 24) y: (875, 3)\n",
      "test x:  (1752, 24) y: (1752, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_one_site_one_factor(factor_index,site_index, out_dir,\n",
    "                                 seq_length_x=24, seq_length_y=24):\n",
    "    pass\n",
    "    # seq_length_x, seq_length_y = 24, 24\n",
    "# pH文件\n",
    "factor_index = 0\n",
    "hdf_file = 'data/water/single/merge' + str(factor_index) +'.h5'\n",
    "# 第一个站点\n",
    "site_index = 0\n",
    "site_names = \"abcdefghijklmnopq\"\n",
    "#\n",
    "out_dir = 'data/water/singlesingle/{}{}'.format(factor_index,site_names[site_index])\n",
    "seq_length_x = 24\n",
    "seq_length_y = 3\n",
    "\n",
    "df = pd.read_hdf(hdf_file)\n",
    "df = df.iloc[:,site_index]\n",
    "x_offsets = np.sort(np.concatenate((np.arange(-(seq_length_x - 1), 1, 1),)))\n",
    "y_offsets = np.sort(np.arange(1, (seq_length_y + 1), 1))\n",
    "\n",
    "num_samples = len(df)\n",
    "data = np.expand_dims(df.values, axis=-1)\n",
    "\n",
    "x, y = [], []\n",
    "min_t = abs(min(x_offsets))\n",
    "max_t = abs(num_samples - abs(max(y_offsets)))  # Exclusive\n",
    "for t in range(min_t, max_t):  # t is the index of the last observation.\n",
    "    x.append(data[t + x_offsets, ...])\n",
    "    y.append(data[t + y_offsets, ...])\n",
    "x = np.stack(x, axis=0)\n",
    "y = np.stack(y, axis=0)\n",
    "\n",
    "x = np.squeeze(x)\n",
    "y = np.squeeze(y)\n",
    "\n",
    "print(\"x shape: \", x.shape, \", y shape: \", y.shape)\n",
    "# Write the data into npz file.\n",
    "num_samples = x.shape[0]\n",
    "num_test = round(num_samples * 0.2)\n",
    "num_train = round(num_samples * 0.7)\n",
    "num_val = num_samples - num_test - num_train\n",
    "x_train, y_train = x[:num_train], y[:num_train]\n",
    "x_val, y_val = (\n",
    "    x[num_train: num_train + num_val],\n",
    "    y[num_train: num_train + num_val],\n",
    ")\n",
    "x_test, y_test = x[-num_test:], y[-num_test:]\n",
    "\n",
    "exi =  os.path.exists(out_dir)\n",
    "if not exi:\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "for cat in [\"train\", \"val\", \"test\"]:\n",
    "    _x, _y = locals()[\"x_\" + cat], locals()[\"y_\" + cat]\n",
    "    print(cat, \"x: \", _x.shape, \"y:\", _y.shape)\n",
    "\n",
    "    np.savez_compressed(\n",
    "        os.path.join(out_dir, f\"{cat}.npz\"),\n",
    "        x=_x,\n",
    "        y=_y,\n",
    "        x_offsets=x_offsets.reshape(list(x_offsets.shape) + [1]),\n",
    "        y_offsets=y_offsets.reshape(list(y_offsets.shape) + [1]),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "LSTM(\n",
      "  24, 3, batch_first=True\n",
      "  (input_drop): VariationalDropout()\n",
      "  (output_drop): VariationalDropout()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "dataloader = util.load_dataset('data/water/singlesingle/0a',64,64,64,False)\n",
    "\n",
    "\n",
    "# 构建模型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "##### LSTM\n",
    "import utils.better_LSTM as better\n",
    "model = better.LSTM(24,3).to(device)\n",
    "\n",
    "##### MLP\n",
    "# class NeuralNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NeuralNetwork, self).__init__()\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.linear_relu_stack = nn.Sequential(\n",
    "#             nn.Linear(24, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, 3)\n",
    "#         )\n",
    "# \n",
    "#     def forward(self, x):\n",
    "#         x = self.flatten(x)\n",
    "#         logits = self.linear_relu_stack(x)\n",
    "#         return logits\n",
    "# \n",
    "# model = NeuralNetwork().to(device)\n",
    "\n",
    "\n",
    "model = model.double()\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% LSTM\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = util.masked_mae\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    # size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader['train_loader'].get_iterator()):\n",
    "        X = np.expand_dims(X,axis=1)\n",
    "        y = np.expand_dims(y,axis=1)\n",
    "        X = torch.tensor(X).to(device)\n",
    "        y = torch.tensor(y).to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred[0], y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch % 100 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    loss_list = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader['test_loader'].get_iterator():\n",
    "            X = np.expand_dims(X,axis=1)\n",
    "            y = np.expand_dims(y,axis=1)\n",
    "\n",
    "            X = torch.tensor(X).to(device)\n",
    "            y = torch.tensor(y).to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            loss_list.append(loss_fn(pred[0], y).item())\n",
    "\n",
    "    loss_result = np.mean(loss_list)\n",
    "    return loss_result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% 训练\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1,loss:6.164609377554983\n",
      "Epoch:2,loss:6.154703157483261\n",
      "Epoch:3,loss:6.150853947590463\n",
      "Epoch:4,loss:6.148724537239963\n",
      "Epoch:5,loss:6.14731971082741\n",
      "Epoch:6,loss:6.14627814780647\n",
      "Epoch:7,loss:6.145430155527878\n",
      "Epoch:8,loss:6.144676859829291\n",
      "Epoch:9,loss:6.143943897260079\n",
      "Epoch:10,loss:6.14315345809176\n",
      "Epoch:11,loss:6.142189396115213\n",
      "Epoch:12,loss:6.140813307982882\n",
      "Epoch:13,loss:6.138350625485025\n",
      "Epoch:14,loss:6.13168857570564\n",
      "Epoch:15,loss:6.069121620683194\n",
      "Epoch:16,loss:5.915023040683985\n",
      "Epoch:17,loss:5.907125724872873\n",
      "Epoch:18,loss:5.904173404611043\n",
      "Epoch:19,loss:5.902505395163085\n",
      "Epoch:20,loss:5.901383222014642\n",
      "Epoch:21,loss:5.90055159662689\n",
      "Epoch:22,loss:5.899896600253608\n",
      "Epoch:23,loss:5.899358902173646\n",
      "Epoch:24,loss:5.898904182626071\n",
      "Epoch:25,loss:5.898511013504766\n",
      "Epoch:26,loss:5.898165212648844\n",
      "Epoch:27,loss:5.89785695102893\n",
      "Epoch:28,loss:5.89757915699108\n",
      "Epoch:29,loss:5.897326582530264\n",
      "Epoch:30,loss:5.89709522992768\n",
      "Epoch:31,loss:5.896881985208731\n",
      "Epoch:32,loss:5.896684375679052\n",
      "Epoch:33,loss:5.8965004047548675\n",
      "Epoch:34,loss:5.89632843652848\n",
      "Epoch:35,loss:5.896167113250123\n",
      "Epoch:36,loss:5.896015295141157\n",
      "Epoch:37,loss:5.895872015694195\n",
      "Epoch:38,loss:5.89573644792756\n",
      "Epoch:39,loss:5.895607878527357\n",
      "Epoch:40,loss:5.895485687762192\n",
      "Epoch:41,loss:5.8953693336861885\n",
      "Epoch:42,loss:5.895258339571751\n",
      "Epoch:43,loss:5.8951522838061186\n",
      "Epoch:44,loss:5.89505079168967\n",
      "Epoch:45,loss:5.894953528718503\n",
      "Epoch:46,loss:5.894860195037319\n",
      "Epoch:47,loss:5.894770520823935\n",
      "Epoch:48,loss:5.894684262422045\n",
      "Epoch:49,loss:5.8946011990799025\n",
      "Epoch:50,loss:5.894521130183556\n",
      "Epoch:51,loss:5.894443872896521\n",
      "Epoch:52,loss:5.894369260135859\n",
      "Epoch:53,loss:5.894297138828307\n",
      "Epoch:54,loss:5.894227368401031\n",
      "Epoch:55,loss:5.894159819469906\n",
      "Epoch:56,loss:5.89409437269503\n",
      "Epoch:57,loss:5.89403091777845\n",
      "Epoch:58,loss:5.893969352583368\n",
      "Epoch:59,loss:5.893909582357606\n",
      "Epoch:60,loss:5.893851519046807\n",
      "Epoch:61,loss:5.893795080685278\n",
      "Epoch:62,loss:5.893740190854156\n",
      "Epoch:63,loss:5.893686778198183\n",
      "Epoch:64,loss:5.893634775993692\n",
      "Epoch:65,loss:5.89358412176139\n",
      "Epoch:66,loss:5.893534756918554\n",
      "Epoch:67,loss:5.893486626465909\n",
      "Epoch:68,loss:5.893439678705124\n",
      "Epoch:69,loss:5.89339386498346\n",
      "Epoch:70,loss:5.893349139462447\n",
      "Epoch:71,loss:5.893305458908001\n",
      "Epoch:72,loss:5.893262782499617\n",
      "Epoch:73,loss:5.8932210716566\n",
      "Epoch:74,loss:5.893180289879562\n",
      "Epoch:75,loss:5.893140402605617\n",
      "Epoch:76,loss:5.89310137707585\n",
      "Epoch:77,loss:5.8930631822138855\n",
      "Epoch:78,loss:5.893025788514424\n",
      "Epoch:79,loss:5.8929891679407955\n",
      "Epoch:80,loss:5.892953293830692\n",
      "Epoch:81,loss:5.8929181408092735\n",
      "Epoch:82,loss:5.892883684709013\n",
      "Epoch:83,loss:5.892849902495622\n",
      "Epoch:84,loss:5.892816772199545\n",
      "Epoch:85,loss:5.892784272852514\n",
      "Epoch:86,loss:5.892752384428734\n",
      "Epoch:87,loss:5.892721087790287\n",
      "Epoch:88,loss:5.892690364636406\n",
      "Epoch:89,loss:5.892660197456306\n",
      "Epoch:90,loss:5.892630569485253\n",
      "Epoch:91,loss:5.892601464663622\n",
      "Epoch:92,loss:5.892572867598735\n",
      "Epoch:93,loss:5.892544763529172\n",
      "Epoch:94,loss:5.8925171382914785\n",
      "Epoch:95,loss:5.892489978288973\n",
      "Epoch:96,loss:5.892463270462586\n",
      "Epoch:97,loss:5.892437002263504\n",
      "Epoch:98,loss:5.892411161627529\n",
      "Epoch:99,loss:5.892385736951032\n",
      "Epoch:100,loss:5.892360717068328\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader, model, loss_fn, optimizer)\n",
    "    loss_result = test(dataloader, model, loss_fn)\n",
    "    print(\"Epoch:{},loss:{}\".format(t+1,loss_result))\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}